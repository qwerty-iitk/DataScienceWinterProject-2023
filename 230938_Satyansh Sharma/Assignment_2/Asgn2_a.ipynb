{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO0_v3w3xnyD",
        "outputId": "8eb46b25-0a7f-40b8-ef16-0987b42f2a95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
            "0  15624510    Male   19            19000          0\n",
            "1  15810944    Male   35            20000          0\n",
            "2  15668575  Female   26            43000          0\n",
            "3  15603246  Female   27            57000          0\n",
            "4  15804002    Male   19            76000          0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/Social_Network_Ads.csv')\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gender M and F converted to 0 and 1\n",
        "data['Gender'] = data['Gender'].map({'Male': 1, 'Female': 0})\n",
        "\n",
        "features = data[['Gender', 'Age', 'EstimatedSalary']]\n",
        "target = data['Purchased']"
      ],
      "metadata": {
        "id": "0lYV-L8lxuke"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "V7Np0ozkxwPm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LogisticRegressionScratch:\n",
        "    def __init__(self, learning_rate=0.001, num_iterations=10000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        num_samples, num_features = X.shape\n",
        "        self.weights = np.zeros(num_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.num_iterations):\n",
        "            model = np.dot(X, self.weights) + self.bias\n",
        "            predictions = 1 / (1 + np.exp(-model))  # sigmoid useage\n",
        "\n",
        "            # gradient\n",
        "            dw = (1 / num_samples) * np.dot(X.T, (predictions - y))\n",
        "            db = (1 / num_samples) * np.sum(predictions - y)\n",
        "\n",
        "            # updating weights\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        model = np.dot(X, self.weights) + self.bias\n",
        "        predictions = 1 / (1 + np.exp(-model))\n",
        "        return [1 if i > 0.5 else 0 for i in predictions]"
      ],
      "metadata": {
        "id": "TUUEUvZPxx0G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# normalization\n",
        "\n",
        "scaler_minmax = MinMaxScaler()\n",
        "X_train_normalized = scaler_minmax.fit_transform(X_train)\n",
        "X_test_normalized = scaler_minmax.transform(X_test)\n",
        "\n",
        "# standardization\n",
        "\n",
        "scaler_standard = StandardScaler()\n",
        "X_train_standardized = scaler_standard.fit_transform(X_train)\n",
        "X_test_standardized = scaler_standard.transform(X_test)"
      ],
      "metadata": {
        "id": "RVfzNHQRxzkE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate_model(X_train, X_test, y_train, y_test):\n",
        "    model = LogisticRegressionScratch()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    return accuracy_score(y_test, predictions)\n",
        "\n",
        "#evaluation:\n",
        "accuracy_raw = evaluate_model(X_train, X_test, y_train, y_test)\n",
        "accuracy_normalized = evaluate_model(X_train_normalized, X_test_normalized, y_train, y_test)\n",
        "accuracy_standardized = evaluate_model(X_train_standardized, X_test_standardized, y_train, y_test)\n",
        "\n",
        "print(\"\\nAccuracy with raw data:\", accuracy_raw)\n",
        "print(\"Accuracy with normalized data:\", accuracy_normalized)\n",
        "print(\"Accuracy with standardized data:\", accuracy_standardized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjl9tlM96O29",
        "outputId": "78601c7f-a60e-418b-e2a9-be8327229d22"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-f35eb2a7ae4c>:15: RuntimeWarning: overflow encountered in exp\n",
            "  predictions = 1 / (1 + np.exp(-model))  # sigmoid useage\n",
            "<ipython-input-5-f35eb2a7ae4c>:27: RuntimeWarning: overflow encountered in exp\n",
            "  predictions = 1 / (1 + np.exp(-model))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy with raw data: 0.6083333333333333\n",
            "Accuracy with normalized data: 0.6083333333333333\n",
            "Accuracy with standardized data: 0.8416666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  #trying to improve accuracy (needed?)\n",
        "\n",
        "\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  from sklearn.preprocessing import PolynomialFeatures\n",
        "  from sklearn.pipeline import make_pipeline\n",
        "  from sklearn.metrics import accuracy_score\n",
        "\n",
        "  def apply_logistic_regression(X_train, X_test, y_train, y_test, degree=1):\n",
        "      model = make_pipeline(PolynomialFeatures(degree), LogisticRegression())\n",
        "      model.fit(X_train, y_train)\n",
        "      predictions = model.predict(X_test)\n",
        "      return accuracy_score(y_test, predictions)\n",
        "\n",
        "  accuracy_poly2 = apply_logistic_regression(X_train_standardized, X_test_standardized, y_train, y_test, degree=2)\n",
        "\n",
        "  print(\"Accuracy with degree 2 polynomial:\", accuracy_poly2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo6XSmfW6Qvs",
        "outputId": "3933e400-a2e7-4b8d-8f9c-4a79e542576b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with degree 2 polynomial: 0.9416666666666667\n"
          ]
        }
      ]
    }
  ]
}